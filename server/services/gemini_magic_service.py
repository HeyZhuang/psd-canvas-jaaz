#!/usr/bin/env python3
"""
Gemini é­”æ³•ç”ŸæˆæœåŠ¡
ä½¿ç”¨ Gemini 2.5 Pro API è¿›è¡Œå›¾åƒåˆ†æå’Œé­”æ³•ç”Ÿæˆ
"""

import base64
import json
import os
import re
from typing import Dict, List, Any, Optional
from PIL import Image
from io import BytesIO
import logging

try:
    from google import genai
    from google.genai import types
except ImportError:
    import google.generativeai as genai
    types = None

logger = logging.getLogger(__name__)


class GeminiMagicService:
    """Gemini é­”æ³•ç”ŸæˆæœåŠ¡ç±»"""
    
    def __init__(self, api_key: Optional[str] = None, model_name: Optional[str] = None):
        """
        åˆå§‹åŒ–æœåŠ¡
        
        Args:
            api_key: Gemini APIå¯†é’¥ï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è¯»å–
            model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨ gemini-2.5-pro
        """
        self.api_key = api_key or self._load_api_key_from_config()
        if not self.api_key:
            raise ValueError("éœ€è¦æä¾› Gemini API å¯†é’¥ï¼Œé€šè¿‡å‚æ•°ã€GEMINI_API_KEY ç¯å¢ƒå˜é‡æˆ– config.env æ–‡ä»¶")
        
        # è®¾ç½® API å¯†é’¥å’Œåˆå§‹åŒ–å®¢æˆ·ç«¯
        os.environ["GOOGLE_API_KEY"] = self.api_key
        self.model_name = model_name or os.environ.get("GEMINI_MODEL", "gemini-2.5-pro")
        logger.info(f"âœ… ä½¿ç”¨æ¨¡å‹: {self.model_name}")
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        try:
            # å°è¯•ä½¿ç”¨æ–°ç‰ˆ google-genai SDK
            self.client = genai.Client(api_key=self.api_key)
            self.use_new_sdk = True
            self.genai_old = None
            logger.info("ä½¿ç”¨ google-genai SDK (æ–°ç‰ˆ)")
        except (AttributeError, TypeError) as e:
            # å›é€€åˆ°æ—§ç‰ˆ google-generativeai
            logger.info(f"æ–°ç‰ˆ SDK åˆå§‹åŒ–å¤±è´¥ ({e})ï¼Œå›é€€åˆ°æ—§ç‰ˆ SDK")
            import google.generativeai as genai_old
            self.genai_old = genai_old
            genai_old.configure(api_key=self.api_key)
            self.client = None
            self.use_new_sdk = False
            logger.info("ä½¿ç”¨ google-generativeai SDK (æ—§ç‰ˆ)")
    
    def _load_api_key_from_config(self) -> Optional[str]:
        """ä»é…ç½®æ–‡ä»¶åŠ è½½ API å¯†é’¥"""
        try:
            # é¦–å…ˆå°è¯•ä»ç¯å¢ƒå˜é‡è¯»å–
            api_key = os.environ.get("GEMINI_API_KEY")
            if api_key and api_key not in ["", "YOUR_GEMINI_API_KEY", "your_api_key_here"]:
                logger.info(f"ä»ç¯å¢ƒå˜é‡åŠ è½½ API key: {api_key[:10]}...")
                return api_key
            
            # å°è¯•ä» config.env æ–‡ä»¶è¯»å–
            config_path = os.path.join(
                os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 
                "config.env"
            )
            if os.path.exists(config_path):
                logger.info(f"æ‰¾åˆ°é…ç½®æ–‡ä»¶: {config_path}")
                with open(config_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line.startswith('GEMINI_API_KEY=') and not line.startswith('#'):
                            api_key = line.split('=', 1)[1].strip()
                            if api_key and api_key not in ["", "YOUR_GEMINI_API_KEY", "your_api_key_here"]:
                                logger.info(f"ä»é…ç½®æ–‡ä»¶åŠ è½½ API key: {api_key[:10]}...")
                                return api_key
            else:
                logger.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            
            return None
        except Exception as e:
            logger.warning(f"ä»é…ç½®æ–‡ä»¶è¯»å– API å¯†é’¥å¤±è´¥: {e}")
            return None
    
    def _build_magic_prompt(
        self, 
        canvas_width: int = 0, 
        canvas_height: int = 0,
        layer_info_text: str = "",
        user_request: str = ""
    ) -> str:
        """
        æ„å»ºé­”æ³•ç”Ÿæˆçš„æç¤ºè¯
        å‚è€ƒ prompt.rules çš„ä¸“ä¸šæ ¼å¼
        """
        prompt = f"""# ç”»å¸ƒé­”æ³•ç”Ÿæˆä»»åŠ¡

## ä»»åŠ¡ç›®æ ‡
åˆ†æç”¨æˆ·æä¾›çš„ç”»å¸ƒè®¾è®¡å›¾åƒï¼Œç†è§£è®¾è®¡æ„å›¾å’Œè§†è§‰å…ƒç´ ï¼Œå¹¶æä¾›ä¸“ä¸šçš„è®¾è®¡åˆ†æå’Œæ”¹è¿›å»ºè®®ã€‚

## ç”»å¸ƒä¿¡æ¯
- **ç”»å¸ƒå°ºå¯¸**: {canvas_width}x{canvas_height} (å®½xé«˜)
{f"- **ç°æœ‰å›¾å±‚ä¿¡æ¯**:\n```\n{layer_info_text}\n```\n" if layer_info_text else ""}

## ç”¨æˆ·éœ€æ±‚
{user_request if user_request else "è¯·åˆ†æè¿™ä¸ªè®¾è®¡å¹¶æä¾›æ”¹è¿›å»ºè®®"}

## åˆ†æè¦æ±‚

### 1. è®¾è®¡ç†è§£
è¯·æ·±å…¥åˆ†æå›¾åƒï¼ŒåŒ…æ‹¬ï¼š
- **è®¾è®¡ç±»å‹**: è¯†åˆ«è®¾è®¡çš„ç”¨é€”ï¼ˆæµ·æŠ¥ã€UIç•Œé¢ã€äº§å“å±•ç¤ºã€ç¤¾äº¤åª’ä½“å›¾ç­‰ï¼‰
- **ä¸»è¦å…ƒç´ **: åˆ—å‡ºæ‰€æœ‰å…³é”®è§†è§‰å…ƒç´ ï¼ˆæ–‡å­—ã€å›¾å½¢ã€å›¾ç‰‡ã€è£…é¥°ç­‰ï¼‰
- **è‰²å½©æ–¹æ¡ˆ**: åˆ†æä¸»è‰²è°ƒå’Œé…è‰²æ–¹æ¡ˆ
- **è®¾è®¡é£æ ¼**: è¯†åˆ«è®¾è®¡é£æ ¼ï¼ˆç°ä»£ç®€çº¦ã€å¤å¤ã€ç§‘æŠ€æ„Ÿã€æ‰‹ç»˜é£ç­‰ï¼‰
- **æ„å›¾æ–¹å¼**: åˆ†ææ„å›¾å¸ƒå±€ï¼ˆå±…ä¸­ã€é»„é‡‘åˆ†å‰²ã€å¯¹ç§°ã€ç•™ç™½ç­‰ï¼‰

### 2. è®¾è®¡è¯„ä¼°
è¯„ä¼°å½“å‰è®¾è®¡çš„ä¼˜åŠ¿å’Œä¸è¶³ï¼š
- **ä¼˜ç‚¹**: è®¾è®¡ä¸­åšå¾—å¥½çš„åœ°æ–¹
- **å¯æ”¹è¿›ç‚¹**: éœ€è¦ä¼˜åŒ–çš„æ–¹é¢
- **ç¼ºå¤±å…ƒç´ **: å¯ä»¥æ·»åŠ çš„å…ƒç´ æ¥æå‡è®¾è®¡

### 3. é­”æ³•å»ºè®®
æä¾›å…·ä½“çš„æ”¹è¿›æ–¹æ¡ˆï¼š
- **é¢œè‰²ä¼˜åŒ–**: å¦‚ä½•æ”¹è¿›é…è‰²
- **å¸ƒå±€è°ƒæ•´**: å¦‚ä½•ä¼˜åŒ–å…ƒç´ å¸ƒå±€
- **æ–°å¢å…ƒç´ **: å»ºè®®æ·»åŠ ä»€ä¹ˆå…ƒç´ 
- **è§†è§‰å±‚æ¬¡**: å¦‚ä½•å¢å¼ºè§†è§‰å±‚æ¬¡æ„Ÿ
- **ç”¨æˆ·ä½“éªŒ**: å¦‚ä½•æå‡æ•´ä½“ä½“éªŒ

### 4. å›¾åƒç”Ÿæˆæç¤ºè¯
åŸºäºåˆ†æç»“æœï¼Œç”Ÿæˆä¸€ä¸ªä¸“ä¸šçš„è‹±æ–‡æç¤ºè¯ï¼Œç”¨äº AI å›¾åƒç”Ÿæˆå·¥å…·åˆ›å»ºé…å¥—çš„è§†è§‰å…ƒç´ æˆ–æ”¹è¿›ç‰ˆæœ¬ã€‚
æç¤ºè¯è¦æ±‚ï¼š
- è¯¦ç»†æè¿°è§†è§‰é£æ ¼
- åŒ…å«å…³é”®å…ƒç´ å’Œæ„å›¾
- æŒ‡å®šè‰²å½©æ–¹æ¡ˆ
- é€‚åˆ DALL-Eã€Midjourneyã€Stable Diffusion ç­‰å·¥å…·

## è¾“å‡ºæ ¼å¼è¦æ±‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼š

```json
{{
  "design_analysis": {{
    "design_type": "è®¾è®¡ç±»å‹ï¼ˆå¦‚ï¼šç”µå•†æµ·æŠ¥ã€Appç•Œé¢ã€äº§å“å±•ç¤ºç­‰ï¼‰",
    "main_elements": ["ä¸»è¦å…ƒç´ 1", "ä¸»è¦å…ƒç´ 2", "ä¸»è¦å…ƒç´ 3"],
    "color_scheme": {{
      "primary_colors": ["#é¢œè‰²1", "#é¢œè‰²2"],
      "secondary_colors": ["#é¢œè‰²3", "#é¢œè‰²4"],
      "description": "é…è‰²æè¿°"
    }},
    "design_style": "è®¾è®¡é£æ ¼æè¿°",
    "composition": "æ„å›¾æ–¹å¼æè¿°",
    "visual_hierarchy": "è§†è§‰å±‚æ¬¡åˆ†æ"
  }},
  "evaluation": {{
    "strengths": ["ä¼˜ç‚¹1", "ä¼˜ç‚¹2", "ä¼˜ç‚¹3"],
    "weaknesses": ["ä¸è¶³1", "ä¸è¶³2"],
    "missing_elements": ["ç¼ºå¤±å…ƒç´ 1", "ç¼ºå¤±å…ƒç´ 2"]
  }},
  "magic_suggestions": [
    {{
      "category": "é¢œè‰²ä¼˜åŒ–|å¸ƒå±€è°ƒæ•´|æ–°å¢å…ƒç´ |è§†è§‰å±‚æ¬¡|å…¶ä»–",
      "title": "å»ºè®®æ ‡é¢˜",
      "description": "è¯¦ç»†æè¿°",
      "priority": "é«˜|ä¸­|ä½",
      "implementation": "å…·ä½“å®æ–½æ–¹æ³•"
    }}
  ],
  "image_generation_prompt": "Professional [design type] with [key elements], featuring [color scheme], [composition style], [additional details], high quality, detailed, 4k",
  "layer_operations": [
    {{
      "operation": "add|modify|delete|move|resize",
      "target": "ç›®æ ‡å›¾å±‚æˆ–æ–°å¢å…ƒç´ ",
      "parameters": {{
        "description": "æ“ä½œæè¿°",
        "reason": "æ“ä½œåŸå› "
      }}
    }}
  ],
  "summary": "æ•´ä½“è®¾è®¡æ€»ç»“å’Œæ ¸å¿ƒå»ºè®®ï¼ˆ100å­—ä»¥å†…ï¼‰"
}}
```

**é‡è¦**: 
1. è¯·ç›´æ¥è¾“å‡º JSON å¯¹è±¡ï¼Œä¸è¦æ·»åŠ  markdown ä»£ç å—æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰
2. ç¡®ä¿è¾“å‡ºæ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼
3. æ‰€æœ‰å­—æ®µéƒ½å¿…é¡»å¡«å†™ï¼Œä¸èƒ½çœç•¥
4. åˆ†æè¦ä¸“ä¸šã€å…·ä½“ã€å¯æ“ä½œ
5. å›¾åƒç”Ÿæˆæç¤ºè¯å¿…é¡»æ˜¯è‹±æ–‡ï¼Œä¸”è¶³å¤Ÿè¯¦ç»†
"""
        return prompt
    
    async def generate_magic_analysis(
        self,
        image_base64: str,
        canvas_width: int = 0,
        canvas_height: int = 0,
        layer_info: Optional[List[Dict[str, Any]]] = None,
        user_request: str = ""
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ Gemini è¿›è¡Œé­”æ³•åˆ†æ
        
        Args:
            image_base64: ç”»å¸ƒæˆªå›¾çš„ base64 ç¼–ç ï¼ˆä¸å«å‰ç¼€ï¼‰
            canvas_width: ç”»å¸ƒå®½åº¦
            canvas_height: ç”»å¸ƒé«˜åº¦
            layer_info: å›¾å±‚ä¿¡æ¯åˆ—è¡¨
            user_request: ç”¨æˆ·çš„è‡ªå®šä¹‰éœ€æ±‚
        
        Returns:
            åŒ…å«åˆ†æç»“æœçš„å­—å…¸
        """
        try:
            logger.info("ğŸ¨ å¼€å§‹ Gemini é­”æ³•åˆ†æ...")
            
            # æ„å»ºå›¾å±‚ä¿¡æ¯æ–‡æœ¬
            layer_info_text = ""
            if layer_info:
                layer_info_text = self._format_layer_info(layer_info)
            
            # æ„å»ºæç¤ºè¯
            prompt = self._build_magic_prompt(
                canvas_width=canvas_width,
                canvas_height=canvas_height,
                layer_info_text=layer_info_text,
                user_request=user_request
            )
            
            # è°ƒç”¨ Gemini API
            response_text = await self.call_gemini_api(
                prompt=prompt,
                image_base64=image_base64,
                temperature=0.3,  # ç¨é«˜çš„æ¸©åº¦ä»¥è·å¾—æ›´æœ‰åˆ›æ„çš„å»ºè®®
                max_tokens=8192
            )
            
            logger.info(f"âœ… Gemini API è°ƒç”¨æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(response_text)}")
            
            # è§£æ JSON å“åº”
            result = self._parse_json_response(response_text)
            
            if result:
                logger.info("âœ… é­”æ³•åˆ†æå®Œæˆ")
                return {
                    "success": True,
                    "data": result
                }
            else:
                logger.warning("âš ï¸ JSON è§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å“åº”")
                return {
                    "success": False,
                    "error": "JSON è§£æå¤±è´¥",
                    "raw_response": response_text
                }
                
        except Exception as e:
            logger.error(f"âŒ é­”æ³•åˆ†æå¤±è´¥: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e)
            }
    
    def _format_layer_info(self, layer_info: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–å›¾å±‚ä¿¡æ¯ä¸ºæ–‡æœ¬"""
        lines = ["ID | åç§° | ç±»å‹ | å¯è§ | åæ ‡(L,T,R,B) | å°ºå¯¸(WxH)"]
        lines.append("-" * 70)
        
        for layer in layer_info:
            layer_id = layer.get('id', '?')
            name = layer.get('name', 'Unknown')
            layer_type = layer.get('type', 'unknown')
            visible = 'âœ“' if layer.get('visible', True) else 'âœ—'
            
            # è·å–åæ ‡
            bounds = layer.get('bounds', {})
            left = bounds.get('left', 0)
            top = bounds.get('top', 0)
            right = bounds.get('right', 0)
            bottom = bounds.get('bottom', 0)
            width = right - left
            height = bottom - top
            
            lines.append(
                f"{layer_id} | {name[:20]} | {layer_type} | {visible} | "
                f"({left},{top},{right},{bottom}) | {width}x{height}"
            )
        
        return "\n".join(lines)
    
    def _parse_json_response(self, response_text: str) -> Optional[Dict[str, Any]]:
        """è§£æ Gemini è¿”å›çš„ JSON å“åº”"""
        try:
            # å°è¯•ç›´æ¥è§£æ
            return json.loads(response_text)
        except json.JSONDecodeError:
            # å°è¯•æå– JSON å—
            logger.warning("ç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå– JSON å—")
            
            # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
            cleaned = re.sub(r'```json\s*', '', response_text)
            cleaned = re.sub(r'```\s*', '', cleaned)
            cleaned = cleaned.strip()
            
            try:
                return json.loads(cleaned)
            except json.JSONDecodeError:
                # å°è¯•æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
                start = cleaned.find('{')
                end = cleaned.rfind('}')
                
                if start != -1 and end != -1:
                    json_str = cleaned[start:end+1]
                    try:
                        return json.loads(json_str)
                    except json.JSONDecodeError:
                        logger.error("æ‰€æœ‰ JSON è§£æå°è¯•å‡å¤±è´¥")
                        return None
                
                logger.error("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ JSON å¯¹è±¡")
                return None
    
    async def call_gemini_api(
        self,
        prompt: str,
        image_base64: str,
        temperature: float = 0.3,
        max_tokens: int = 8192,
        max_retries: int = 3,
        timeout: int = 120
    ) -> str:
        """
        è°ƒç”¨ Gemini API
        
        Args:
            prompt: æç¤ºè¯
            image_base64: å›¾åƒçš„ base64 ç¼–ç ï¼ˆä¸å«å‰ç¼€ï¼‰
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§è¾“å‡º token æ•°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        
        Returns:
            API å“åº”æ–‡æœ¬
        """
        import time
        import asyncio
        
        for attempt in range(max_retries):
            try:
                # å‡†å¤‡å›¾åƒæ•°æ®
                image_data = base64.b64decode(image_base64)
                image = Image.open(BytesIO(image_data))
                
                logger.info(f"ğŸ“¸ å›¾åƒå°ºå¯¸: {image.size}, æ ¼å¼: {image.format}")
                
                async def _make_api_call():
                    if self.use_new_sdk and self.client:
                        # ä½¿ç”¨æ–°ç‰ˆ google-genai SDK
                        logger.info(f"ä½¿ç”¨æ–°ç‰ˆ SDK è°ƒç”¨ Gemini API (è¶…æ—¶: {timeout}ç§’)")
                        
                        response = self.client.models.generate_content(
                            model=self.model_name,
                            contents=[prompt, image],
                            config=types.GenerateContentConfig(
                                temperature=temperature,
                                max_output_tokens=max_tokens,
                                response_modalities=["Text"]
                            )
                        )
                        
                        # æå–å“åº”æ–‡æœ¬
                        return response.text
                    else:
                        # ä½¿ç”¨æ—§ç‰ˆ google-generativeai SDK
                        logger.info(f"ä½¿ç”¨æ—§ç‰ˆ SDK è°ƒç”¨ Gemini API (è¶…æ—¶: {timeout}ç§’)")
                        
                        model = self.genai_old.GenerativeModel(self.model_name)
                        
                        # ç”Ÿæˆå†…å®¹
                        response = model.generate_content(
                            [prompt, image],
                            generation_config={
                                "temperature": temperature,
                                "max_output_tokens": max_tokens,
                            }
                        )
                        
                        return response.text
                
                # ä½¿ç”¨ asyncio.wait_for æ·»åŠ è¶…æ—¶æ§åˆ¶
                try:
                    result = await asyncio.wait_for(_make_api_call(), timeout=timeout)
                    logger.info(f"âœ… API è°ƒç”¨æˆåŠŸï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰")
                    return result
                except asyncio.TimeoutError:
                    logger.warning(f"â±ï¸ API è°ƒç”¨è¶…æ—¶ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰")
                    if attempt < max_retries - 1:
                        wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                        logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                        await asyncio.sleep(wait_time)
                        continue
                    else:
                        raise TimeoutError(f"API è°ƒç”¨è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
                        
            except Exception as e:
                logger.error(f"âŒ API è°ƒç”¨å¤±è´¥ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰: {e}")
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt
                    logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    await asyncio.sleep(wait_time)
                else:
                    raise
        
        raise Exception("è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")


# å…¨å±€å•ä¾‹
_gemini_magic_service: Optional[GeminiMagicService] = None


def get_gemini_magic_service() -> GeminiMagicService:
    """è·å– Gemini é­”æ³•æœåŠ¡å•ä¾‹"""
    global _gemini_magic_service
    if _gemini_magic_service is None:
        _gemini_magic_service = GeminiMagicService()
    return _gemini_magic_service





